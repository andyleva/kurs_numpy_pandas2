{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e12a783",
   "metadata": {},
   "source": [
    "# Домашнее задание\n",
    "### по Уроку 3. Построение модели классификации."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad70a44e",
   "metadata": {},
   "source": [
    "### Для чего и в каких случаях полезны различные варианты усреднения для метрик качества классификации: micro, macro, weighted?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf45a4e",
   "metadata": {},
   "source": [
    "при дисбалансе классов, для уточнения влияния каждого класса на метрику\n",
    "\n",
    "Для несбалансированных классовых задач:\n",
    "Используйтся микро-усреднение для взвешивания вашей метрики по отношению к самой большой.\n",
    "Используйтся макросреднение для взвешивания вашей метрики в сторону наименьшей (если беспокоит классовый дисбаланс)\n",
    "Используется weighted - взвешивание по конкретным классам\n",
    "\n",
    "micro говорит, что дает каждой паре выборка-класс равный вклад в общую метрику (за исключением результата взвешивания выборки). Вместо того, чтобы суммировать метрику для каждого класса, это суммирует дивиденды и делители, составляющие метрики для каждого класса, для расчета общего частного. Микро-усреднение может быть предпочтительным в настройках с несколькими ярлыками, включая многоклассовую классификацию, когда класс большинства следует игнорировать.\n",
    "микро-среднее может быть полезной мерой, когда ваш набор данных различается по размеру. \n",
    "micro = точность. чувствительна к дисбалансу класса (Если ваша цель состоит в том , чтобы ваш классификатор просто максимизировал свои попадания и минимизировал свои промахи)\n",
    "\n",
    "macro вычисляет среднее значение двоичных показателей, придавая каждому классу одинаковый вес. В задачах, где редкие классы не менее важны, макро-усреднение может быть средством выделения их производительности. С другой стороны, предположение, что все классы одинаково важны, часто неверно, так что макро-усреднение будет чрезмерно подчеркивать обычно низкую производительность для нечастого класса.\n",
    "Макро-усреднение заключается в том, чтобы сначала вычислить значение статистического индекса для каждой категории, а затем вычислить среднее арифметическое всех категорий. На макро-средние показатели больше влияют малые категории, чем на микросредние показатели.\n",
    "Проблема с множественной классификацией, не подверженная дисбалансу данных, легко затрагивается категориями с высокой узнаваемостью (высокая отзывчивость, высокая точность);\n",
    "не чувствительна к дисбалансу класса (если вы больше всего цените меньший класс)\n",
    "\n",
    "weighted учитывает дисбаланс классов, вычисляя среднее значение двоичных показателей, в которых оценка каждого класса взвешивается по его присутствию в истинной выборке данных.\n",
    "\n",
    "\"микро\" ближе к \"точности\", в то время как \"макро\" немного отличается, когда в нем не доминирует преобладающий класс"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0709480f",
   "metadata": {},
   "source": [
    "### В чём разница между моделями xgboost, lightgbm и catboost или какие их основные особенности?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d6df628",
   "metadata": {},
   "source": [
    "XGBoost - создает слабое дерево, а затем \"бустирует\" последующие деревья, чтобы уменьшить остаточные ошибки. пытается фиксировать и устранять любые шаблоны ошибок до сих пор, пока они не окажутся случайными. \n",
    "Библиотека XGBoost параллелизуема.\n",
    "Маштабирование не требуется. Категориальные данные нужно кодировать.\n",
    "Можно использовать в работе графический процессор"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da948756",
   "metadata": {},
   "source": [
    "LightGBM - использует механизм выборки, уменьшает использование памяти, увеличивает глубину деревьев (по листьм, а не по уровню), может использовать несколько процессоров. Строит деревья, по где больше ошибок, туда дерево идет дальше.\n",
    "Использует подходы GOSS (GOSS смотрит на градиенты различных разрезов, влияющих на функцию потерь, и обновляет дерево подстройки в соответствии с выбором самых больших градиентов и случайно отобранных малых градиентов, GOSS позволяет LightGBM быстро находить наиболее влиятельные разрезы) и EFB\n",
    "LightGBM как и CatBoost также может обрабатывать категориальные функции, вводя имена функций. Он не конвертируется в одноразовое кодирование и намного быстрее, чем одноразовое кодирование. LGBM использует специальный алгоритм, чтобы найти значение разделения категориальных признаков"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe1bc27b",
   "metadata": {},
   "source": [
    "CatBoost - фокусируется на оптимизации деревьев решений для категориальных переменных или переменных, различные значения которых могут не иметь никакой связи друг с другом.\n",
    "в деревьях используются симмитричные вопросы.\n",
    "CatBoost будет самостоятельно обрабатывать все категориальные столбцы как числовые переменные.\n",
    "Лучшая производительность.\n",
    "Предоставляет возможность визуализации"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
